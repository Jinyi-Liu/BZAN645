{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation\n",
    "In this case, we model $p(t|x,y)$ by a neural network. In the pet adoption case, $x$ is the feature of the pet and $y$ is the adoption speed. The $t$ is the type of the pet, i.e., cat or dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/app/Final/code\"\n",
    "# path = \".\"\n",
    "# This is the dataset processed from the midterm\n",
    "train_size = 14993\n",
    "data_df = pd.read_csv(path + \"/data/data_df_proc.csv\")[:train_size]\n",
    "data_df.head()\n",
    "\n",
    "cols_to_drop = [\"Name\", \"RescuerID\", \"VideoAmt\", \"Description\", \"PetID\", \"PhotoAmt\"]\n",
    "to_drop_columns = [\n",
    "    \"PetID\",\n",
    "    \"Name\",\n",
    "    \"RescuerID\",\n",
    "    \"Description\",\n",
    "    \"BreedName_full\",\n",
    "    \"Breed1Name\",\n",
    "    \"Breed2Name\",\n",
    "]\n",
    "data_df.drop(cols_to_drop + to_drop_columns, axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "data_df.fillna(data_df.mean(), inplace=True)\n",
    "\n",
    "# Embedding the categorical variables using nn.Embedding\n",
    "cat_cols = [\n",
    "    \"Breed1\",\n",
    "    \"Breed2\",\n",
    "    \"Gender\",\n",
    "    \"Color1\",\n",
    "    \"Color2\",\n",
    "    \"Color3\",\n",
    "    \"State\",\n",
    "    \"Breed_full\",\n",
    "    \"Color_full\",\n",
    "    \"hard_interaction\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for cat_col in cat_cols:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    data_df[cat_col] = label_encoders[cat_col].fit_transform(data_df[cat_col])\n",
    "\n",
    "# Normalize the continuous variables\n",
    "# cont_cols = data_df.columns.difference(cat_cols + [\"AdoptionSpeed\"])\n",
    "# data_df[cont_cols] = data_df[cont_cols].apply(\n",
    "#     lambda x: (x - x.mean()) / x.std(), axis=0\n",
    "# )\n",
    "\n",
    "emb_c = {n: len(col.unique()) for n, col in data_df.items() if n in cat_cols}\n",
    "emb_cols = emb_c.keys()  # names of columns chosen for embedding\n",
    "emb_szs = [\n",
    "    (c, min(20, (c + 1) // 2)) for _, c in emb_c.items()\n",
    "]  # embedding sizes for the chosen columns\n",
    "\n",
    "# Split data into train and validation by AdoptionSpeed and stratify\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    data_df, test_size=0.2, random_state=42, stratify=data_df[\"AdoptionSpeed\"]\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=\"AdoptionSpeed\")\n",
    "y_train = train_df[\"AdoptionSpeed\"]\n",
    "X_valid = valid_df.drop(columns=\"AdoptionSpeed\")\n",
    "y_valid = valid_df[\"AdoptionSpeed\"]\n",
    "\n",
    "n_cont = len(X_train.columns) - len(emb_cols)  # number of continuous columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PetFinderModel(emb_szs, n_cont)\n",
    "device = get_default_device()\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_ds = PetFinderData(X_train, y_train, emb_cols)\n",
    "valid_ds = PetFinderData(X_valid, y_valid, emb_cols)\n",
    "\n",
    "# Get data into device\n",
    "batch_size = 512\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)\n",
    "\n",
    "\n",
    "# Train model\n",
    "epochs = 5000\n",
    "history = train_loop(\n",
    "    model, epochs=epochs, lr=0.00005, wd=0.0001, train_dl=train_dl, valid_dl=valid_dl\n",
    ")\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"./model-stratify.pt\")\n",
    "# Save history\n",
    "history = np.array(history)\n",
    "np.save(\"./history.npy\", history)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# range(epochs)\n",
    "plt.plot(range(epochs), history[:, 0], label=\"train_loss\")\n",
    "plt.plot(range(epochs), history[:, 2], label=\"val_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig(path + \"/figure/loss-statify.png\")\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(range(epochs), history[:, 1], label=\"train_kappa\")\n",
    "plt.plot(range(epochs), history[:, 3], label=\"val_kappa\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Kappa\")\n",
    "plt.title(\"Quadratic Weighted Kappa vs Epochs\")\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig(path + \"/figure/kappa-stratify.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural network\n",
    "Now we have the data to estimate $p(t|x,y)$ where $t$ is the type of the pet, $y$ is the adoption speed and $x$ is the remaining columns in data_df. We use a neural network to model $p(t|x,y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_setting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding the categorical variables using nn.Embedding\n",
    "cat_cols = ['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'State', 'Breed_full','Color_full', 'hard_interaction']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for cat_col in cat_cols:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    data_df[cat_col] = label_encoders[cat_col].fit_transform(data_df[cat_col])\n",
    "    \n",
    "emb_c = {n: len(col.unique()) for n,col in data_df.items() if n in cat_cols}\n",
    "emb_cols = emb_c.keys() # names of columns chosen for embedding\n",
    "emb_szs = [(c, min(30, (c+1)//2)) for _,c in emb_c.items()] #embedding sizes for the chosen columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation\n",
    "train_df = data_df.iloc[:len(data_df)*4//5, :]\n",
    "valid_df = data_df.iloc[len(data_df)*4//5:, :]\n",
    "train_df.shape, valid_df.shape\n",
    "\n",
    "\n",
    "X_train = train_df.drop(columns='AdoptionSpeed')\n",
    "y_train = train_df['AdoptionSpeed']\n",
    "X_valid = valid_df.drop(columns='AdoptionSpeed')\n",
    "y_valid = valid_df['AdoptionSpeed']\n",
    "\n",
    "n_cont = len(X_train.columns)-len(emb_cols) # number of continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetFinderModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(176, 30)\n",
       "    (1): Embedding(135, 30)\n",
       "    (2): Embedding(3, 2)\n",
       "    (3-4): 2 x Embedding(7, 4)\n",
       "    (5): Embedding(6, 3)\n",
       "    (6): Embedding(14, 7)\n",
       "    (7): Embedding(812, 30)\n",
       "    (8): Embedding(63, 30)\n",
       "    (9): Embedding(142, 30)\n",
       "  )\n",
       "  (lin1): Linear(in_features=328, out_features=200, bias=True)\n",
       "  (lin2): Linear(in_features=200, out_features=30, bias=True)\n",
       "  (lin4): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (bn1): SELU()\n",
       "  (bn2): SELU()\n",
       "  (bn3): SELU()\n",
       "  (bn4): SELU()\n",
       "  (emb_drop): Dropout(p=0.2, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PetFinderModel(emb_szs, n_cont)\n",
    "device = get_default_device()\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PetFinderData(X_train, y_train, emb_cols)\n",
    "valid_ds = PetFinderData(X_valid, y_valid, emb_cols)\n",
    "\n",
    "# Get data into device\n",
    "batch_size = 512\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 3.647\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.569\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.570\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.570\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.569\n",
      "valid loss 3.659 and accuracy 0.279\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=5, lr=0.005, wd=0.0001, train_dl=train_dl, valid_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(),'./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
