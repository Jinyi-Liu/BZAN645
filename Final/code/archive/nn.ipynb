{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation\n",
    "In this case, we model $p(t|x,y)$ by a neural network. In the pet adoption case, $x$ is the feature of the pet and $y$ is the adoption speed. The $t$ is the type of the pet, i.e., cat or dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '/app/code'\n",
    "# path='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "data_df = pd.read_csv(path+'/data/train/train.csv')\n",
    "# data_df.columns\n",
    "cols_to_drop = ['Name','RescuerID','VideoAmt','Description','PetID','PhotoAmt']\n",
    "data_df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "data_df['Type'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0     1    3     299       0       1       1       7       0             1   \n",
       "1     1    1     265       0       1       1       2       0             2   \n",
       "2     0    1     307       0       1       2       7       0             2   \n",
       "3     0    4     307       0       2       1       2       0             2   \n",
       "4     0    1     307       0       1       1       0       0             2   \n",
       "\n",
       "   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n",
       "0          1           2         2           2       1         1  100  41326   \n",
       "1          2           3         3           3       1         1    0  41401   \n",
       "2          2           1         1           2       1         1    0  41326   \n",
       "3          1           1         1           2       1         1  150  41401   \n",
       "4          1           2         2           2       1         1    0  41326   \n",
       "\n",
       "   AdoptionSpeed  \n",
       "0              2  \n",
       "1              0  \n",
       "2              3  \n",
       "3              2  \n",
       "4              2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural network\n",
    "Now we have the data to estimate $p(t|x,y)$ where $t$ is the type of the pet, $y$ is the adoption speed and $x$ is the remaining columns in data_df. We use a neural network to model $p(t|x,y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as torch_optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding the categorical variables using nn.Embedding\n",
    "cat_cols = ['Breed1','Breed2','Color1','Color2','Color3','State']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for cat_col in cat_cols:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    data_df[cat_col] = label_encoders[cat_col].fit_transform(data_df[cat_col])\n",
    "    \n",
    "emb_c = {n: len(col.unique()) for n,col in data_df.items() if n in cat_cols}\n",
    "emb_cols = emb_c.keys() # names of columns chosen for embedding\n",
    "emb_szs = [(c, min(10, (c+1)//2)) for _,c in emb_c.items()] #embedding sizes for the chosen columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation\n",
    "train_df = data_df.iloc[:len(data_df)*4//5, :]\n",
    "valid_df = data_df.iloc[len(data_df)*4//5:, :]\n",
    "train_df.shape, valid_df.shape\n",
    "\n",
    "X_train = train_df.drop(columns='Type')\n",
    "y_train = train_df['Type']\n",
    "X_valid = valid_df.drop(columns='Type')\n",
    "y_valid = valid_df['Type']\n",
    "\n",
    "# X_train = train_df.drop(columns='AdoptionSpeed')\n",
    "# y_train = train_df['AdoptionSpeed']\n",
    "# X_valid = valid_df.drop(columns='AdoptionSpeed')\n",
    "# y_valid = valid_df['AdoptionSpeed']\n",
    "\n",
    "n_cont = len(X_train.columns)-len(emb_cols) # number of continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderData(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols):\n",
    "        X = X.copy()\n",
    "        self.X1 = torch.tensor(X.loc[:,emb_cols].copy().values).long() #categorical columns\n",
    "        self.X2 = torch.tensor(X.drop(columns=emb_cols).copy().values).float() #numerical columns\n",
    "        self.y = torch.tensor(Y.values).to(torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 200)\n",
    "        self.lin2 = nn.Linear(200, 30)\n",
    "        self.lin4 = nn.Linear(30, 1)\n",
    "        # self.lin4 = nn.Sequential(nn.Linear(30, 1), nn.Softmax(dim=1))\n",
    "        self.bn1 = nn.SELU()\n",
    "        self.bn2 = nn.SELU()\n",
    "        self.bn3 = nn.SELU()\n",
    "        self.bn4 = nn.SELU()\n",
    "        self.emb_drop = nn.Dropout(0.2)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        \n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.drops(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.bn3(x)      \n",
    "        x = self.drops(x)  \n",
    "        # x = self.lin3(x)\n",
    "        # x = self.bn4(x)\n",
    "        # x = self.drops(x)\n",
    "        x = self.lin4(x)\n",
    "        # map x to [0,4]\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.0001, wd = 0.0):\n",
    "    optim = torch_optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x1, x2, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        output = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(output, y.view(-1,1))\n",
    "        # loss = F.cross_entropy(output, y.view(-1,1))\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        output = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(output, y.view(-1,1))\n",
    "        # loss = F.cross_entropy(output, y.view(-1,1))\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.round(torch.max(output, 1)[0])\n",
    "        correct += (pred == y).float().sum().item()\n",
    "\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, lr=0.01, wd=0.01, train_dl=None, valid_dl=None):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"training loss: %.3f\"  % loss)\n",
    "        val_loss(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetFinderModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(176, 10)\n",
       "    (1): Embedding(135, 10)\n",
       "    (2-3): 2 x Embedding(7, 4)\n",
       "    (4): Embedding(6, 3)\n",
       "    (5): Embedding(14, 7)\n",
       "  )\n",
       "  (lin1): Linear(in_features=49, out_features=200, bias=True)\n",
       "  (lin2): Linear(in_features=200, out_features=30, bias=True)\n",
       "  (lin4): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (bn1): SELU()\n",
       "  (bn2): SELU()\n",
       "  (bn3): SELU()\n",
       "  (bn4): SELU()\n",
       "  (emb_drop): Dropout(p=0.2, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PetFinderModel(emb_szs, n_cont)\n",
    "device = get_default_device()\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PetFinderData(X_train, y_train, emb_cols)\n",
    "valid_ds = PetFinderData(X_valid, y_valid, emb_cols)\n",
    "\n",
    "# Get data into device\n",
    "batch_size = 512\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.532\n",
      "valid loss 0.524 and accuracy 0.983\n",
      "training loss: 0.535\n",
      "valid loss 0.526 and accuracy 0.980\n",
      "training loss: 0.534\n",
      "valid loss 0.531 and accuracy 0.965\n",
      "training loss: 0.534\n",
      "valid loss 0.523 and accuracy 0.988\n",
      "training loss: 0.534\n",
      "valid loss 0.524 and accuracy 0.985\n",
      "training loss: 0.533\n",
      "valid loss 0.531 and accuracy 0.967\n",
      "training loss: 0.531\n",
      "valid loss 0.525 and accuracy 0.981\n",
      "training loss: 0.530\n",
      "valid loss 0.532 and accuracy 0.962\n",
      "training loss: 0.532\n",
      "valid loss 0.526 and accuracy 0.979\n",
      "training loss: 0.529\n",
      "valid loss 0.526 and accuracy 0.980\n",
      "training loss: 0.530\n",
      "valid loss 0.529 and accuracy 0.973\n",
      "training loss: 0.529\n",
      "valid loss 0.524 and accuracy 0.984\n",
      "training loss: 0.529\n",
      "valid loss 0.528 and accuracy 0.973\n",
      "training loss: 0.529\n",
      "valid loss 0.522 and accuracy 0.990\n",
      "training loss: 0.529\n",
      "valid loss 0.525 and accuracy 0.982\n",
      "training loss: 0.528\n",
      "valid loss 0.525 and accuracy 0.982\n",
      "training loss: 0.528\n",
      "valid loss 0.529 and accuracy 0.971\n",
      "training loss: 0.531\n",
      "valid loss 0.526 and accuracy 0.979\n",
      "training loss: 0.528\n",
      "valid loss 0.529 and accuracy 0.971\n",
      "training loss: 0.531\n",
      "valid loss 0.528 and accuracy 0.974\n",
      "training loss: 0.528\n",
      "valid loss 0.521 and accuracy 0.992\n",
      "training loss: 0.529\n",
      "valid loss 0.522 and accuracy 0.990\n",
      "training loss: 0.529\n",
      "valid loss 0.525 and accuracy 0.981\n",
      "training loss: 0.528\n",
      "valid loss 0.525 and accuracy 0.981\n",
      "training loss: 0.526\n",
      "valid loss 0.522 and accuracy 0.993\n",
      "training loss: 0.531\n",
      "valid loss 0.522 and accuracy 0.989\n",
      "training loss: 0.526\n",
      "valid loss 0.523 and accuracy 0.986\n",
      "training loss: 0.526\n",
      "valid loss 0.523 and accuracy 0.987\n",
      "training loss: 0.526\n",
      "valid loss 0.525 and accuracy 0.981\n",
      "training loss: 0.526\n",
      "valid loss 0.522 and accuracy 0.990\n",
      "training loss: 0.528\n",
      "valid loss 0.525 and accuracy 0.981\n",
      "training loss: 0.525\n",
      "valid loss 0.520 and accuracy 0.995\n",
      "training loss: 0.531\n",
      "valid loss 0.530 and accuracy 0.968\n",
      "training loss: 0.528\n",
      "valid loss 0.524 and accuracy 0.986\n",
      "training loss: 0.526\n",
      "valid loss 0.520 and accuracy 0.993\n",
      "training loss: 0.527\n",
      "valid loss 0.526 and accuracy 0.980\n",
      "training loss: 0.525\n",
      "valid loss 0.524 and accuracy 0.985\n",
      "training loss: 0.525\n",
      "valid loss 0.523 and accuracy 0.986\n",
      "training loss: 0.525\n",
      "valid loss 0.520 and accuracy 0.996\n",
      "training loss: 0.524\n",
      "valid loss 0.524 and accuracy 0.985\n",
      "training loss: 0.525\n",
      "valid loss 0.527 and accuracy 0.976\n",
      "training loss: 0.528\n",
      "valid loss 0.522 and accuracy 0.990\n",
      "training loss: 0.526\n",
      "valid loss 0.522 and accuracy 0.991\n",
      "training loss: 0.526\n",
      "valid loss 0.525 and accuracy 0.988\n",
      "training loss: 0.526\n",
      "valid loss 0.522 and accuracy 0.990\n",
      "training loss: 0.524\n",
      "valid loss 0.522 and accuracy 0.990\n",
      "training loss: 0.524\n",
      "valid loss 0.524 and accuracy 0.984\n",
      "training loss: 0.525\n",
      "valid loss 0.521 and accuracy 0.991\n",
      "training loss: 0.524\n",
      "valid loss 0.521 and accuracy 0.992\n",
      "training loss: 0.524\n",
      "valid loss 0.521 and accuracy 0.993\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=50, lr=0.005, wd=0.0001, train_dl=train_dl, valid_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(),'./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x1, x2, y in valid_dl:\n",
    "#     output = model(x1, x2)\n",
    "#     pred = torch.max(output, 1)\n",
    "#     # correct += (pred == y).float().sum().item()\n",
    "#     print(pred)\n",
    "#     print(y)\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
