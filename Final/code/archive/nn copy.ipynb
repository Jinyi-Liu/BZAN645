{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation\n",
    "In this case, we model $p(t|x,y)$ by a neural network. In the pet adoption case, $x$ is the feature of the pet and $y$ is the adoption speed. The $t$ is the type of the pet, i.e., cat or dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '/app/Final/code'\n",
    "# path='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>RESCUER_avg_photo_STD</th>\n",
       "      <th>RESCUER_Sterilized_MEAN</th>\n",
       "      <th>RESCUER_Dewormed_MEAN</th>\n",
       "      <th>RESCUER_Vaccinated_MEAN</th>\n",
       "      <th>INTERACTION_Fee_MEAN</th>\n",
       "      <th>INTERACTION_Fee_MIN</th>\n",
       "      <th>INTERACTION_Fee_MAX</th>\n",
       "      <th>INTERACTION_avg_fee_MEAN</th>\n",
       "      <th>INTERACTION_avg_fee_STD</th>\n",
       "      <th>INTERACTION_avg_fee_MAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.438579</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>9.860575</td>\n",
       "      <td>37.517683</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.621302</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>7.029586</td>\n",
       "      <td>49.694115</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.179079</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>38.650330</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>37.996073</td>\n",
       "      <td>101.708699</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.707039</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>37.690031</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>36.557373</td>\n",
       "      <td>114.952243</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.233783</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>7.871345</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>6.997772</td>\n",
       "      <td>35.615495</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize  ...  RESCUER_avg_photo_STD  RESCUER_Sterilized_MEAN  \\\n",
       "0             1  ...               1.060660                 0.000000   \n",
       "1             2  ...                    NaN                      NaN   \n",
       "2             2  ...               2.179079                 0.144796   \n",
       "3             2  ...               4.707039                 0.300000   \n",
       "4             2  ...               1.233783                 0.046875   \n",
       "\n",
       "   RESCUER_Dewormed_MEAN  RESCUER_Vaccinated_MEAN  INTERACTION_Fee_MEAN  \\\n",
       "0               0.000000                 0.000000             10.438579   \n",
       "1                    NaN                      NaN              7.621302   \n",
       "2               0.959184                 0.952941             38.650330   \n",
       "3               0.877551                 0.489796             37.690031   \n",
       "4               0.795455                 0.750000              7.871345   \n",
       "\n",
       "   INTERACTION_Fee_MIN  INTERACTION_Fee_MAX  INTERACTION_avg_fee_MEAN  \\\n",
       "0                    0                  500                  9.860575   \n",
       "1                    0                  500                  7.029586   \n",
       "2                    0                  700                 37.996073   \n",
       "3                    0                 1500                 36.557373   \n",
       "4                    0                  500                  6.997772   \n",
       "\n",
       "  INTERACTION_avg_fee_STD  INTERACTION_avg_fee_MAX  \n",
       "0               37.517683                    500.0  \n",
       "1               49.694115                    500.0  \n",
       "2              101.708699                    700.0  \n",
       "3              114.952243                   1000.0  \n",
       "4               35.615495                    500.0  \n",
       "\n",
       "[5 rows x 178 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the dataset processed from the midterm \n",
    "train_size = 14993\n",
    "data_df = pd.read_csv(path + '/data/data_df_proc.csv')[:train_size]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "# data_df = pd.read_csv(path+'/data/train/train.csv')\n",
    "# data_df.columns\n",
    "cols_to_drop = ['Name','RescuerID','VideoAmt','Description','PetID','PhotoAmt']\n",
    "to_drop_columns = ['PetID', 'Name', 'RescuerID', 'Description',\n",
    "                    'BreedName_full','Breed1Name','Breed2Name']\n",
    "data_df.drop(cols_to_drop+to_drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with the NaN values\n",
    "data_df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural network\n",
    "Now we have the data to estimate $p(t|x,y)$ where $t$ is the type of the pet, $y$ is the adoption speed and $x$ is the remaining columns in data_df. We use a neural network to model $p(t|x,y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as torch_optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding the categorical variables using nn.Embedding\n",
    "cat_cols = ['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'State', 'Breed_full','Color_full', 'hard_interaction']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for cat_col in cat_cols:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    data_df[cat_col] = label_encoders[cat_col].fit_transform(data_df[cat_col])\n",
    "    \n",
    "emb_c = {n: len(col.unique()) for n,col in data_df.items() if n in cat_cols}\n",
    "emb_cols = emb_c.keys() # names of columns chosen for embedding\n",
    "emb_szs = [(c, min(30, (c+1)//2)) for _,c in emb_c.items()] #embedding sizes for the chosen columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation\n",
    "train_df = data_df.iloc[:len(data_df)*4//5, :]\n",
    "valid_df = data_df.iloc[len(data_df)*4//5:, :]\n",
    "train_df.shape, valid_df.shape\n",
    "\n",
    "\n",
    "X_train = train_df.drop(columns='AdoptionSpeed')\n",
    "y_train = train_df['AdoptionSpeed']\n",
    "X_valid = valid_df.drop(columns='AdoptionSpeed')\n",
    "y_valid = valid_df['AdoptionSpeed']\n",
    "\n",
    "n_cont = len(X_train.columns)-len(emb_cols) # number of continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderData(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols):\n",
    "        X = X.copy()\n",
    "        self.X1 = torch.tensor(X.loc[:,emb_cols].copy().values).long() #categorical columns\n",
    "        self.X2 = torch.tensor(X.drop(columns=emb_cols).copy().values).float() #numerical columns\n",
    "        self.y = torch.tensor(Y.values).to(torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 200)\n",
    "        self.lin2 = nn.Linear(200, 30)\n",
    "        self.lin4 = nn.Linear(30, 1)\n",
    "        # self.lin4 = nn.Sequential(nn.Linear(30, 1), nn.Softmax(dim=1))\n",
    "        self.bn1 = nn.SELU()\n",
    "        self.bn2 = nn.SELU()\n",
    "        self.bn3 = nn.SELU()\n",
    "        self.bn4 = nn.SELU()\n",
    "        self.emb_drop = nn.Dropout(0.2)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        \n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.drops(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.bn3(x)      \n",
    "        x = self.drops(x)  \n",
    "        # x = self.lin3(x)\n",
    "        # x = self.bn4(x)\n",
    "        # x = self.drops(x)\n",
    "        x = self.lin4(x)\n",
    "        # map x to [0,4]\n",
    "        x = torch.sigmoid(x)*4\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.0001, wd = 0.0):\n",
    "    optim = torch_optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x1, x2, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        # print(batch)\n",
    "        output = model(x1, x2)\n",
    "        loss = F.mse_loss(output, y.view(-1,1))\n",
    "        # print(output, y.view(-1,1))\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        output = model(x1, x2)\n",
    "\n",
    "        loss = F.mse_loss(output, y.view(-1,1))\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.round(output)[0]\n",
    "        # pred = torch.round(torch.max(output, 1)[0])\n",
    "        correct += (pred == y).float().sum().item()\n",
    "\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, lr=0.01, wd=0.01, train_dl=None, valid_dl=None):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"training loss: %.3f\"  % loss)\n",
    "        val_loss(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetFinderModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(176, 30)\n",
       "    (1): Embedding(135, 30)\n",
       "    (2): Embedding(3, 2)\n",
       "    (3-4): 2 x Embedding(7, 4)\n",
       "    (5): Embedding(6, 3)\n",
       "    (6): Embedding(14, 7)\n",
       "    (7): Embedding(812, 30)\n",
       "    (8): Embedding(63, 30)\n",
       "    (9): Embedding(142, 30)\n",
       "  )\n",
       "  (lin1): Linear(in_features=328, out_features=200, bias=True)\n",
       "  (lin2): Linear(in_features=200, out_features=30, bias=True)\n",
       "  (lin4): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (bn1): SELU()\n",
       "  (bn2): SELU()\n",
       "  (bn3): SELU()\n",
       "  (bn4): SELU()\n",
       "  (emb_drop): Dropout(p=0.2, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PetFinderModel(emb_szs, n_cont)\n",
    "device = get_default_device()\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PetFinderData(X_train, y_train, emb_cols)\n",
    "valid_ds = PetFinderData(X_valid, y_valid, emb_cols)\n",
    "\n",
    "# Get data into device\n",
    "batch_size = 512\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 3.647\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.569\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.570\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.570\n",
      "valid loss 3.659 and accuracy 0.279\n",
      "training loss: 3.569\n",
      "valid loss 3.659 and accuracy 0.279\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=5, lr=0.005, wd=0.0001, train_dl=train_dl, valid_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(),'./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x1, x2, y in valid_dl:\n",
    "#     output = model(x1, x2)\n",
    "#     pred = torch.max(output, 1)\n",
    "#     # correct += (pred == y).float().sum().item()\n",
    "#     print(pred)\n",
    "#     print(y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
